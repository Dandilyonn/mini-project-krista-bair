{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1d14057",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph.checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoints\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msqlite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MemorySaver\n\u001b[32m     11\u001b[39m load_dotenv()\n\u001b[32m     12\u001b[39m openai.api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langgraph.checkpoints'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langgraph.checkpoints.sqlite import MemorySaver\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "memory = MemorySaver(\"chat_memory.sqlite\")\n",
    "\n",
    "\n",
    "class TravelPlan(BaseModel):\n",
    "    destination: str\n",
    "    date: str\n",
    "    budget: str\n",
    "    preferences: List[str]\n",
    "    itinerary_suggestions: List[str]\n",
    "    travel_tips: List[str]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cabbca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph.checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoints\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msqlite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MemorySaver\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Load API key\u001b[39;00m\n\u001b[32m     11\u001b[39m load_dotenv()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langgraph.checkpoints'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langgraph.checkpoints.sqlite import MemorySaver\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "memory = MemorySaver(\"chat_memory.sqlite\")\n",
    "\n",
    "class TravelPlan(BaseModel):\n",
    "    destination: str\n",
    "    date: str\n",
    "    budget: str\n",
    "    preferences: List[str]\n",
    "    itinerary_suggestions: List[str]\n",
    "    travel_tips: List[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4386e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_flow = [\n",
    "    (\"destination\", \"Hi! I'm here to help you plan your trip. Where would you like to go?\"),\n",
    "    (\"date\", \"When do you plan to travel?\"),\n",
    "    (\"budget\", \"What is your travel budget?\"),\n",
    "    (\"preferences\", \"What activities do you enjoy? (e.g., museums, nature, food, nightlife)?\")\n",
    "]\n",
    "\n",
    "def next_prompt(state):\n",
    "    for key, prompt in question_flow:\n",
    "        if not state.get(key):\n",
    "            return key, prompt\n",
    "    state[\"complete\"] = True\n",
    "    return None, \"I think I have everything I need. Would you like me to generate your travel plan now?\"\n",
    "\n",
    "def trim_messages(history, limit=10):\n",
    "    return history[-limit:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ea691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_chat_completion(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        stream=True\n",
    "    )\n",
    "    full_reply = \"\"\n",
    "    for chunk in response:\n",
    "        delta = chunk['choices'][0]['delta']\n",
    "        if \"content\" in delta:\n",
    "            print(delta[\"content\"], end='', flush=True)\n",
    "            full_reply += delta[\"content\"]\n",
    "    print() \n",
    "    return full_reply\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7978b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plan(state):\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful travel planner.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "Based on this user's travel details:\n",
    "Destination: {state['destination']}\n",
    "Date: {state['date']}\n",
    "Budget: {state['budget']}\n",
    "Preferences: {', '.join(state['preferences'])}\n",
    "\n",
    "Please return:\n",
    "- 3 personalized itinerary suggestions (bullet list)\n",
    "- 3 travel tips (bullet list)\n",
    "\"\"\"}\n",
    "    ]\n",
    "    print(\"\\nGenerating travel plan...\\n\")\n",
    "    response = stream_chat_completion(prompt)\n",
    "\n",
    "    itinerary = []\n",
    "    tips = []\n",
    "    lines = response.split(\"\\n\")\n",
    "    current = itinerary\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip(\"-â€¢ \").strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if \"tip\" in line.lower():\n",
    "            current = tips\n",
    "        else:\n",
    "            current.append(line)\n",
    "\n",
    "    plan = TravelPlan(\n",
    "        destination=state[\"destination\"],\n",
    "        date=state[\"date\"],\n",
    "        budget=state[\"budget\"],\n",
    "        preferences=state[\"preferences\"],\n",
    "        itinerary_suggestions=itinerary[:3],\n",
    "        travel_tips=tips[:3] or [\"Stay safe!\", \"Respect local customs\", \"Stick to your budget\"]\n",
    "    )\n",
    "\n",
    "    print(\"\\nFinal Travel Plan:\")\n",
    "    print(json.dumps(plan.dict(), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1185f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chat():\n",
    "    print(\"Welcome to the Travel Planning Chatbot!\\n\")\n",
    "\n",
    "    # Restore from LangGraph memory or start new\n",
    "    state = memory.get(\"user_session\") or {\n",
    "        \"destination\": None,\n",
    "        \"date\": None,\n",
    "        \"budget\": None,\n",
    "        \"preferences\": [],\n",
    "        \"complete\": False\n",
    "    }\n",
    "\n",
    "    message_history = []\n",
    "\n",
    "    while not state[\"complete\"]:\n",
    "        key, prompt = next_prompt(state)\n",
    "        print(prompt)\n",
    "\n",
    "        user_input = input(\"> \").strip()\n",
    "\n",
    "        message_history.append({\"role\": \"assistant\", \"content\": prompt})\n",
    "        message_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        message_history = trim_messages(message_history)\n",
    "\n",
    "        if key == \"preferences\":\n",
    "            state[key] = [x.strip() for x in user_input.split(\",\")]\n",
    "        elif key:\n",
    "            state[key] = user_input\n",
    "        elif user_input.lower() in [\"yes\", \"y\"]:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Okay, let me know when you're ready.\")\n",
    "            continue\n",
    "\n",
    "        memory.put(\"user_session\", state)\n",
    "\n",
    "    state[\"complete\"] = True\n",
    "    memory.put(\"user_session\", state)\n",
    "    generate_plan(state)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
